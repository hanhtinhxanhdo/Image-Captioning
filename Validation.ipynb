{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available (Torch).\n",
      "Current GPU: GeForce GTX 1080 Ti\n",
      "No GPU found. Using CPU. (Tensorflow)\n"
     ]
    }
   ],
   "source": [
    "import torch, tensorflow as tf\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available (Torch).\")\n",
    "    _device = torch.device(\"cuda\")\n",
    "    print(\"Current GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"No GPU found. Using CPU.\")\n",
    "    _device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "# Check if GPU is available\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"GPU is available (Tensorflow).\")\n",
    "    print(\"GPU Devices:\")\n",
    "    for device in tf.config.list_physical_devices('GPU'):\n",
    "        print(device)\n",
    "else:\n",
    "    print(\"No GPU found. Using CPU. (Tensorflow)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from pycocotools.coco import COCO\n",
    "import urllib, zipfile\n",
    "from nlp_utils import *\n",
    "\n",
    "from models import EncoderCNN_Resnet50, EncoderCNN_VGG19, DecoderRNN\n",
    "from Data_loader import *\n",
    "from torchvision import transforms\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import pickle5 as pickle\n",
    "import matplotlib.pyplot as plt \n",
    "import skimage.io as io \n",
    "import numpy as np \n",
    "%matplotlib inline \n",
    "from Data_loader_val import get_loader as val_get_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the saved checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=1.39s)\n",
      "creating index...\n",
      "index created!\n",
      "[0/414113] Tokenizing captions...\n",
      "[100000/414113] Tokenizing captions...\n",
      "[200000/414113] Tokenizing captions...\n",
      "[300000/414113] Tokenizing captions...\n",
      "[400000/414113] Tokenizing captions...\n",
      "loading annotations into memory...\n",
      "Done (t=0.82s)\n",
      "creating index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 397/414113 [00:00<01:44, 3969.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index created!\n",
      "Obtaining caption lengths...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 414113/414113 [01:36<00:00, 4281.73it/s]\n"
     ]
    }
   ],
   "source": [
    "embed_size=256\n",
    "hidden_size = 512\n",
    "batch_size=128\n",
    "vocab_threshold=8\n",
    "transform_train = transforms.Compose([ \n",
    "    transforms.Resize(256),                          # smaller edge of image resized to 256\n",
    "    transforms.RandomCrop(224),                      # get 224x224 crop from random location\n",
    "    transforms.RandomHorizontalFlip(),               # horizontally flip image with probability=0.5\n",
    "    transforms.ToTensor(),                           # convert the PIL Image to a tensor\n",
    "    transforms.Normalize((0.485, 0.456, 0.406),      # normalize image for pre-trained model\n",
    "                         (0.229, 0.224, 0.225))])\n",
    "# Obtain the data loader.\n",
    "data_loader = get_loader(transform=transform_train,\n",
    "                         mode='train',\n",
    "                         batch_size=batch_size,\n",
    "                         vocab_threshold=vocab_threshold,\n",
    "                         vocab_from_file=False,\n",
    "                         cocoapi_loc = 'opt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataloader for test data :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary successfully loaded from vocab.pkl file!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecoderRNN(\n",
       "  (embed): Embedding(7072, 256)\n",
       "  (lstm): LSTM(256, 512, batch_first=True)\n",
       "  (linear): Linear(in_features=512, out_features=7072, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(data_loader.dataset.vocab)\n",
    "\n",
    "model_save_path = \"checkpoint_resnet50\"\n",
    "\n",
    "# Define a transform to pre-process the training images.\n",
    "transform_test = transforms.Compose([ \n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.ToTensor(),                           # convert the PIL Image to a tensor\n",
    "    transforms.Normalize((0.485, 0.456, 0.406),      # normalize image for pre-trained model\n",
    "                         (0.229, 0.224, 0.225))])\n",
    "\n",
    "# Obtain the data loader.\n",
    "val_data_loader = val_get_loader(transform=transform_test, mode='valid', cocoapi_loc='opt')\n",
    "encoder_file = \"encoderdata_1.pkl\"\n",
    "decoder_file = \"decoderdata_1.pkl\"\n",
    "\n",
    "encoder = EncoderCNN_Resnet50(embed_size)\n",
    "decoder = DecoderRNN(embed_size, hidden_size, vocab_size)\n",
    "\n",
    "# Moving models to GPU if CUDA is available.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "\n",
    "# Loading the trained weights\n",
    "encoder.load_state_dict(torch.load(os.path.join(model_save_path, encoder_file)))\n",
    "decoder.load_state_dict(torch.load(os.path.join(model_save_path, decoder_file)))\n",
    "\n",
    "encoder.eval()\n",
    "decoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40504/40504 [57:16<00:00, 11.79it/s]  \n"
     ]
    }
   ],
   "source": [
    "# infer captions for all images\n",
    "pred_result = defaultdict(list)\n",
    "for img_id, img in tqdm(val_data_loader):\n",
    "    img = img.to(device)\n",
    "#     print(img.shape)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        features = encoder(img).unsqueeze(1)\n",
    "#         print(features.shape)\n",
    "#         break\n",
    "        output = decoder.sample(features)\n",
    "    sentence = clean_sentence(output, val_data_loader.dataset.vocab.idx2word)\n",
    "    pred_result[img_id.item()].append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('opt', \"cocoapi\", \"annotations/captions_val2014.json\"), \"r\") as f:\n",
    "    caption = json.load(f)\n",
    "\n",
    "valid_annot = caption[\"annotations\"]\n",
    "valid_result = defaultdict(list)\n",
    "for i in valid_annot:\n",
    "    valid_result[i[\"image_id\"]].append(i[\"caption\"].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['a bicycle replica with a clock as the front wheel.',\n",
       "  'the bike has a clock as a tire.',\n",
       "  'a black metal bicycle with a clock inside the front wheel.',\n",
       "  'a bicycle figurine in which the front wheel is replaced with a clock\\n',\n",
       "  'a clock with the appearance of the wheel of a bicycle '],\n",
       " ['a black honda motorcycle parked in front of a garage.',\n",
       "  'a honda motorcycle parked in a grass driveway',\n",
       "  'a black honda motorcycle with a dark burgundy seat.',\n",
       "  'ma motorcycle parked on the gravel in front of a garage',\n",
       "  'a motorcycle with its brake extended standing outside'],\n",
       " ['a room with blue walls and a white sink and door.',\n",
       "  'blue and white color scheme in a small bathroom.',\n",
       "  'this is a blue and white bathroom with a wall sink and a lifesaver on the wall.',\n",
       "  'a blue boat themed bathroom with a life preserver on the wall',\n",
       "  'a bathroom with walls that are painted baby blue.'],\n",
       " ['a car that seems to be parked illegally behind a legally parked car',\n",
       "  'two cars parked on the sidewalk on the street',\n",
       "  'city street with parked cars and a bench.',\n",
       "  'cars try to maneuver into parking spaces along a densely packed city street. ',\n",
       "  'a couple of cars parked in a busy street sidewalk.']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(valid_result.values())[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[' a bench sitting on a park bench in a park.'],\n",
       " [' a giraffe standing in the middle of a field.'],\n",
       " [' a man in a suit and tie standing in a room.'],\n",
       " [' a man in a kitchen preparing food on a table.']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(pred_result.values())[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17755527547985703"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_score(true_sentences=valid_result, predicted_sentences=pred_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
